#!/usr/bin/env python3
"""
PaSST (Patchout Spectrogram Transformer) ã®åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ
SSLè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼å¯¾å¿œç‰ˆ
"""

import ssl
import os
import numpy as np
import torch

# SSLè¨¼æ˜æ›¸ã®æ¤œè¨¼ã‚’ç„¡åŠ¹åŒ–ï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

# ç’°å¢ƒå¤‰æ•°ã§ã‚‚è¨­å®š
os.environ['PYTHONHTTPSVERIFY'] = '0'

from hear21passt.base import get_basic_model

def test_basic_model():
    """åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨æ¨è«–ãƒ†ã‚¹ãƒˆ"""

    print("=" * 50)
    print("PaSST Model Basic Test (SSL Fix)")
    print("=" * 50)

    # 1. ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    print("\n1. Loading PaSST model...")
    try:
        # logitsãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆAudioSetã®527ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰
        model = get_basic_model(mode="logits")
        model.eval()

        # ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"   Device: {device}")
        model = model.to(device)

        print("   âœ… Model loaded successfully!")

    except Exception as e:
        print(f"   âŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        return

    # 2. ãƒ€ãƒŸãƒ¼ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    print("\n2. Creating dummy audio data...")
    # PaSSTã¯32kHzã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’æœŸå¾…ï¼ˆ10ç§’é–“ï¼‰
    sample_rate = 32000
    duration = 10  # seconds
    audio_length = sample_rate * duration

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªä¿¡å·ã‚’ç”Ÿæˆï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º1ï¼‰
    audio_wave = torch.randn(1, audio_length).to(device)
    print(f"   Audio shape: {audio_wave.shape}")
    print(f"   Sample rate: {sample_rate} Hz")
    print(f"   Duration: {duration} seconds")

    # 3. æ¨è«–ã®å®Ÿè¡Œ
    print("\n3. Running inference...")
    try:
        with torch.no_grad():
            logits = model(audio_wave)

        print(f"   Output shape: {logits.shape}")
        print(f"   Number of classes: {logits.shape[-1]}")

        # Softmaxã§ç¢ºç‡ã«å¤‰æ›
        probs = torch.softmax(logits, dim=-1)

        # Top-5ã®äºˆæ¸¬ã‚’å–å¾—
        top5_probs, top5_indices = torch.topk(probs[0], 5)

        print("\n   Top-5 predictions (indices):")
        for i, (idx, prob) in enumerate(zip(top5_indices.cpu().numpy(), top5_probs.cpu().numpy())):
            print(f"   {i+1}. Class {idx}: {prob:.4f}")

        print("\n   âœ… Inference successful!")

    except Exception as e:
        print(f"   âŒ Inference failed: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—
    print("\n4. Model information:")
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"   Total parameters: {total_params:,}")
    print(f"   Trainable parameters: {trainable_params:,}")

    print("\n" + "=" * 50)
    print("âœ… All tests passed successfully!")
    print("=" * 50)

    return model

if __name__ == "__main__":
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    model = test_basic_model()

    print("\nğŸ‰ PaSST model is ready to use!")

    if model is not None:
        print("\nModel architecture summary:")
        print(f"  - Model class: {model.__class__.__name__}")
        print(f"  - Input: 32kHz audio")
        print(f"  - Output: 527 AudioSet classes")